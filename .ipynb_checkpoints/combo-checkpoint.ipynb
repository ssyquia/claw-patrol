{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faab3c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 16:01:43.406642: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-04-28 16:01:43.406850: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2024-04-28 16:01:43.406861: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
      "2024-04-28 16:01:43.406970: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-28 16:01:43.407059: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-04-28 16:01:56.022987: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.stderr = open(os.devnull, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c896ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm # Fancy progress bars\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "\n",
    "import cv2 \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras import layers \n",
    "from functools import partial \n",
    "\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead686b6",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cb1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bdb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "data_train = 'data_train'\n",
    "data_val = 'data_valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3ab25e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m\n\u001b[1;32m      2\u001b[0m val_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      5\u001b[0m     class_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, class_name)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(class_dir):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "for class_name in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    os.makedirs(os.path.join(data_train, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(data_val, class_name), exist_ok=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(class_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    train_index = int(len(image_files) * train_ratio)\n",
    "    val_index = int(len(image_files) * val_ratio) + train_index\n",
    "\n",
    "    train_images = image_files[:train_index]\n",
    "    val_images = image_files[train_index:val_index]\n",
    "\n",
    "    for image in train_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dst = os.path.join(data_train, class_name, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    for image in val_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dst = os.path.join(data_val, class_name, image)\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fc0fd29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.DS_S</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tyrannosaurus_Rex/Tyrannosaurus_Rex_12</td>\n",
       "      <td>Tyrannosaurus_Rex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tyrannosaurus_Rex/Tyrannosaurus_Rex_140</td>\n",
       "      <td>Tyrannosaurus_Rex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tyrannosaurus_Rex/Tyrannosaurus_Rex_154</td>\n",
       "      <td>Tyrannosaurus_Rex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tyrannosaurus_Rex/Tyrannosaurus_Rex_9</td>\n",
       "      <td>Tyrannosaurus_Rex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>Brachiosaurus/Brachiosaurus_10</td>\n",
       "      <td>Brachiosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>Brachiosaurus/Brachiosaurus_162</td>\n",
       "      <td>Brachiosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2446</th>\n",
       "      <td>Brachiosaurus/Brachiosaurus_163</td>\n",
       "      <td>Brachiosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>Brachiosaurus/Brachiosaurus_11</td>\n",
       "      <td>Brachiosaurus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>Brachiosaurus/Brachiosaurus_39</td>\n",
       "      <td>Brachiosaurus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           id              breed\n",
       "0                                       .DS_S               data\n",
       "1      Tyrannosaurus_Rex/Tyrannosaurus_Rex_12  Tyrannosaurus_Rex\n",
       "2     Tyrannosaurus_Rex/Tyrannosaurus_Rex_140  Tyrannosaurus_Rex\n",
       "3     Tyrannosaurus_Rex/Tyrannosaurus_Rex_154  Tyrannosaurus_Rex\n",
       "4       Tyrannosaurus_Rex/Tyrannosaurus_Rex_9  Tyrannosaurus_Rex\n",
       "...                                       ...                ...\n",
       "2444           Brachiosaurus/Brachiosaurus_10      Brachiosaurus\n",
       "2445          Brachiosaurus/Brachiosaurus_162      Brachiosaurus\n",
       "2446          Brachiosaurus/Brachiosaurus_163      Brachiosaurus\n",
       "2447           Brachiosaurus/Brachiosaurus_11      Brachiosaurus\n",
       "2448           Brachiosaurus/Brachiosaurus_39      Brachiosaurus\n",
       "\n",
       "[2449 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "folders = [data_train, data_val]\n",
    "\n",
    "for r, d, f in os.walk(data_dir):\n",
    "    for file in f:\n",
    "        breed = r.split('/')[-1]\n",
    "        path = os.path.join(r,file)\n",
    "        identify = os.path.join(r[5:],file)[:-4]\n",
    "        data.append((identify, breed))\n",
    "\n",
    "labels = pd.DataFrame(data,columns=['id','breed'])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a684d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 breed   id\n",
      "4        Dilophosaurus  176\n",
      "2        Compsognathus  171\n",
      "3        Corythosaurus  169\n",
      "8   Pachycephalosaurus  167\n",
      "9      Parasaurolophus  167\n",
      "12         Triceratops  167\n",
      "10         Spinosaurus  166\n",
      "1        Brachiosaurus  163\n",
      "5          Dimorphodon  161\n",
      "11         Stegosaurus  161\n",
      "13   Tyrannosaurus_Rex  161\n",
      "0         Ankylosaurus  159\n",
      "14        Velociraptor  158\n",
      "6           Gallimimus  151\n",
      "7         Microceratus  151\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "NUM_CLASSES = 15\n",
    "SEED = 7\n",
    "\n",
    "selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
    "labels = labels[labels['breed'].isin(selected_breed_list)]\n",
    "labels['target'] = 1\n",
    "group = labels.groupby(by='breed', as_index=False).agg({'id': pd.Series.nunique})\n",
    "group = group.sort_values('id',ascending=False)\n",
    "print(group)\n",
    "labels['rank'] = group['breed']\n",
    "labels_pivot = labels.pivot(index='id', columns='breed', values='target').reset_index().fillna(0)\n",
    "\n",
    "np.random.seed(seed=SEED)\n",
    "rnd = np.random.random(len(labels))\n",
    "\n",
    "# Train / validation split into 80%/20%\n",
    "train_idx = rnd < 0.8\n",
    "valid_idx = rnd >= 0.8\n",
    "y_train = labels_pivot[selected_breed_list].values\n",
    "ytr = y_train[train_idx]\n",
    "yv = y_train[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fd9a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fff51c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_img(img_id, size):\n",
    "    \"\"\"\n",
    "    Read and resize image.\n",
    "    # Args:\n",
    "        img_id: image filepath string\n",
    "        train_or_test: string \"train\" or \"test\"\n",
    "        size: resize the original image\n",
    "    # Returns:\n",
    "        Image as a numpy array\n",
    "    \"\"\"\n",
    "    img = image.load_img(join(data_dir, '%s.jpg' % img_id), target_size = size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560eb26f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (2448, 224, 224, 3) size: 368,492,544\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 224\n",
    "POOLING = 'avg'\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype = 'float32')\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "\n",
    "print('Training images shape: {} size: {:,}'.format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c1d20",
   "metadata": {},
   "source": [
    "## Extracting Image Feature-Representations: VGG16 Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3b2c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1966, 224, 224, 3)\n",
      "y_train.shape: (1966, 15)\n",
      "X_val.shape: (482, 224, 224, 3)\n",
      "y_val.shape: (482, 15)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m592s\u001b[0m 10s/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 9s/step\n",
      "VGG training set bottleneck features shape: (1966, 512) size: 1,006,592\n",
      "VGG validation set bottleneck features shape: (482, 512) size: 246,784\n",
      "VGG bottleneck features should be a 512-dimensional vector for each image example / prediction\n"
     ]
    }
   ],
   "source": [
    "# Train / validation split via index\n",
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print(\"X_train.shape: \" + str(Xtr.shape))\n",
    "print(\"y_train.shape: \" + str(ytr.shape))\n",
    "print(\"X_val.shape: \" + str(Xv.shape))\n",
    "print(\"y_val.shape: \" + str(yv.shape))\n",
    "\n",
    "# Extracting image representation bottleneck features (\"bf\")\n",
    "vgg_bottleneck = VGG16(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_vgg_bf = vgg_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_vgg_bf = vgg_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('VGG training set bottleneck features shape: {} size: {:,}'.format(train_vgg_bf.shape, train_vgg_bf.size))\n",
    "print('VGG validation set bottleneck features shape: {} size: {:,}'.format(valid_vgg_bf.shape, valid_vgg_bf.size))\n",
    "print(\"VGG bottleneck features should be a 512-dimensional vector for each image example / prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5194554",
   "metadata": {},
   "source": [
    "## Logistic Regression on Extracted Bottleneck Features: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91546094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation VGG LogLoss 3.9752673897535913\n",
      "Validation VGG Accuracy 0.6141078838174274\n"
     ]
    }
   ],
   "source": [
    "# Optimizer: Limited-memory BFGS\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_vgg_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_vgg_bf)\n",
    "valid_preds = logreg.predict(valid_vgg_bf)\n",
    "\n",
    "print('Validation VGG LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation VGG Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda7783",
   "metadata": {},
   "source": [
    "## Extracting Image Feature-Representations: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc35b933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (2448, 299, 299, 3) size: 656,560,944\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "x_train = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "for i, img_id in tqdm(enumerate(labels['id'])):\n",
    "    img = read_img(img_id, (INPUT_SIZE, INPUT_SIZE))\n",
    "    x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "    x_train[i] = x\n",
    "print(\"Training images shape: {} size: {:,}\".format(x_train.shape, x_train.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e91409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1966, 299, 299, 3)\n",
      "y_train.shape: (1966, 15)\n",
      "X_val.shape: (482, 299, 299, 3)\n",
      "y_val.shape: (482, 15)\n",
      "\u001b[1m 1/62\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19:30\u001b[0m 19s/step"
     ]
    }
   ],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print(\"X_train.shape: \" + str(Xtr.shape))\n",
    "print(\"y_train.shape: \" + str(ytr.shape))\n",
    "print(\"X_val.shape: \" + str(Xv.shape))\n",
    "print(\"y_val.shape: \" + str(yv.shape))\n",
    "\n",
    "xception_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_x_bf = xception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_x_bf = xception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('Xception training bottleneck features shape: {} size: {:,}'.format(train_x_bf.shape, train_x_bf.size))\n",
    "print('Xception validation bottleneck features shape: {} size: {:,}'.format(valid_x_bf.shape, valid_x_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dd4922",
   "metadata": {},
   "source": [
    "## Logistic Regression on Extracted Bottleneck Features: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b3b5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(train_x_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_x_bf)\n",
    "valid_preds = logreg.predict(valid_x_bf)\n",
    "print(\"Validation Xception LogLoss {}\".format(log_loss(yv, valid_probs)))\n",
    "print(\"Validation Xception Accuracy {}\".format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ed71b",
   "metadata": {},
   "source": [
    "## Extracting Image Feature-Representations: Inception Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bef73f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1966, 299, 299, 3)\n",
      "y_train.shape: (1966, 15)\n",
      "X_val.shape: (482, 299, 299, 3)\n",
      "y_val.shape: (482, 15)\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 4s/step\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 3s/step\n",
      "InceptionV3 training bottleneck features shape: (1966, 2048) size: 4,026,368\n",
      "InceptionV3 validation bottleneck features shape: (482, 2048) size: 987,136\n"
     ]
    }
   ],
   "source": [
    "Xtr = x_train[train_idx]\n",
    "Xv = x_train[valid_idx]\n",
    "print(\"X_train.shape: \" + str(Xtr.shape))\n",
    "print(\"y_train.shape: \" + str(ytr.shape))\n",
    "print(\"X_val.shape: \" + str(Xv.shape))\n",
    "print(\"y_val.shape: \" + str(yv.shape))\n",
    "\n",
    "inception_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "train_i_bf = inception_bottleneck.predict(Xtr, batch_size=32, verbose=1)\n",
    "valid_i_bf = inception_bottleneck.predict(Xv, batch_size=32, verbose=1)\n",
    "print('InceptionV3 training bottleneck features shape: {} size: {:,}'.format(train_i_bf.shape, train_i_bf.size))\n",
    "print('InceptionV3 validation bottleneck features shape: {} size: {:,}'.format(valid_i_bf.shape, valid_i_bf.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce28a7",
   "metadata": {},
   "source": [
    "## Logistic Regression on Extracted Bottleneck Features: Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e863b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Inception LogLoss 1.4606565221948267\n",
      "Validation Inception Accuracy 0.6514522821576764\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver = 'lbfgs', random_state=SEED)\n",
    "logreg.fit(train_i_bf, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(valid_i_bf)\n",
    "valid_preds = logreg.predict(valid_i_bf)\n",
    "\n",
    "print('Validation Inception LogLoss {}'.format(log_loss(yv, valid_probs)))\n",
    "print('Validation Inception Accuracy {}'.format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ef768",
   "metadata": {},
   "source": [
    "## Logistic Regression on Combination of Extracted Features: [Xception + Inception]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b91148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full training bottleneck features shape: (1966, 4096) size: 8,052,736\n",
      "Full validation bottleneck features shape: (482, 4096) size: 1,974,272\n",
      "Validation Xception+Inception LogLoss 1.2078942794234089\n",
      "Validation Xception+Inception Accuracy 0.6970954356846473\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([train_x_bf, train_i_bf]) # This is a array-concat function that stacks horizontally instead of vertically\n",
    "V = np.hstack([valid_x_bf, valid_i_bf])\n",
    "print(\"Full training bottleneck features shape: {} size: {:,}\".format(X.shape, X.size))\n",
    "print(\"Full validation bottleneck features shape: {} size: {:,}\".format(V.shape, V.size))\n",
    "\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(X, (ytr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(V)\n",
    "valid_preds = logreg.predict(V)\n",
    "print(\"Validation Xception+Inception LogLoss {}\".format(log_loss(yv, valid_probs)))\n",
    "print(\"Validation Xception+Inception Accuracy {}\".format(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ee918",
   "metadata": {},
   "source": [
    "## Summary and Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1af9201",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m valid_breeds \u001b[38;5;241m=\u001b[39m (\u001b[43myv\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mrange\u001b[39m(NUM_CLASSES))\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m error_idx \u001b[38;5;241m=\u001b[39m (valid_breeds \u001b[38;5;241m!=\u001b[39m valid_preds)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_id, breed, pred \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(labels\u001b[38;5;241m.\u001b[39mloc[valid_idx, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[error_idx],\n\u001b[1;32m      4\u001b[0m                                [selected_breed_list[\u001b[38;5;28mint\u001b[39m(b)] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m valid_preds[error_idx]],\n\u001b[1;32m      5\u001b[0m                                [selected_breed_list[\u001b[38;5;28mint\u001b[39m(b)] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m valid_breeds[error_idx]]):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yv' is not defined"
     ]
    }
   ],
   "source": [
    "valid_breeds = (yv * range(NUM_CLASSES)).sum(axis=1)\n",
    "error_idx = (valid_breeds != valid_preds)\n",
    "for img_id, breed, pred in zip(labels.loc[valid_idx, 'id'].values[error_idx],\n",
    "                               [selected_breed_list[int(b)] for b in valid_preds[error_idx]],\n",
    "                               [selected_breed_list[int(b)] for b in valid_breeds[error_idx]]):\n",
    "    fix, ax = plt.subplots(figsize=(5,5,))\n",
    "    img = read_img(img_id, (299,299))\n",
    "    ax.imshow(img/255)\n",
    "    ax.text(10, 250, 'Prediction: %s' % pred, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.text(10, 270, 'LABEL: %s' % breed, color='k', backgroundcolor='g', alpha=0.8)\n",
    "    ax.text(10, 290, 'Image name: %s' % img_id, color='w', backgroundcolor='r', alpha=0.8)\n",
    "    ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0ffd3",
   "metadata": {},
   "source": [
    "## Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history) \n",
    "\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot() \n",
    "\n",
    "history_df.loc[:, ['auc', 'val_auc']].plot() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7960394",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23f2ba",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = my_model.evaluate(data_validation_set)\n",
    "\n",
    "print(\"Test Loss:\", evaluation_results[0])\n",
    "print(\"Test Accuracy:\", evaluation_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8ad67b",
   "metadata": {},
   "source": [
    "## Test Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dinosaur in image is {} with accuracy of {:0.2f}'.format(dino_names[np.argmax(score)],np.max(score)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd1a84",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34373cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('all_dog_breed_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054f05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
